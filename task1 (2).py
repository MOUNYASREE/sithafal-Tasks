# -*- coding: utf-8 -*-
"""TASK1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RtYgQiCuecrSxZsikRk1xHlKxQYFL2P_
"""

import os
os.chdir('/content')  # Change the current working directory to /content
print(os.getcwd())

with open('.env', 'w') as f:  # 'w' mode for writing
    f.write('GOOGLE_API_KEY="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"')  # Add your API key here

!echo "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" > .env

print(os.listdir())

!ls -a

# Install required libraries
!apt-get install -y tesseract-ocr
!pip install pdfplumber pytesseract pillow pandas

!pip install streamlit
!pip install  google-generativeai
!pip install  python-dotenv
!pip install  langchain
!pip install   PyPDF2
!pip install  chromadb
!pip install   faiss-cpu
!pip install   langchain_google_genai
!pip install -U langchain-community

# Imports
import pdfplumber
import pytesseract
from PIL import Image, ImageEnhance, ImageOps
import pandas as pd
import re

# Function to clean and normalize text
def clean_text(text):
    """
    Clean extracted text by removing excessive spaces, newlines, and invalid symbols.
    """
    text = re.sub(r'\n+', ' ', text)  # Replace newlines
    text = re.sub(r'[^\x00-\x7F]+', '', text)  # Remove non-ASCII
    text = re.sub(r'[^\w\s\.\%\:\$\-]', '', text)  # Keep valid symbols
    text = re.sub(r'\s+', ' ', text).strip()  # Normalize spaces
    return text

# Function to preprocess images for OCR
def preprocess_image_for_ocr(image):
    """
    Preprocess image: grayscale, threshold, contrast enhancement, and resizing.
    """
    image = image.convert("L")  # Grayscale
    image = ImageEnhance.Contrast(image).enhance(2.5)  # Increase contrast
    image = ImageOps.invert(image)  # Invert for better text visibility
    image = image.resize((image.width * 2, image.height * 2), Image.Resampling.LANCZOS)  # Resize
    return image

# OCR function with fallback to different PSM modes
def ocr_page(pdf_path, page_number):
    """
    Perform OCR with preprocessing and adaptive PSM modes.
    """
    try:
        with pdfplumber.open(pdf_path) as pdf:
            page = pdf.pages[page_number]
            image = page.to_image(resolution=300).original
            image = preprocess_image_for_ocr(image)

            # First OCR attempt with PSM 6
            text = pytesseract.image_to_string(image, config="--psm 6")
            if not text.strip():
                # Fallback to PSM 4 for better layout parsing
                text = pytesseract.image_to_string(image, config="--psm 4")
            print(f"OCR performed on Page {page_number + 1}")
            return clean_text(text)
    except Exception as e:
        return f"Error performing OCR on Page {page_number + 1}: {e}"

# Function to dynamically format and align OCR output
def format_ocr_output(text):
    """
    Dynamically format OCR output into structured lines with labels and values.
    """
    # Patterns for degrees, percentages, and monetary values
    degree_pattern = r'(Doctoral|Professional|Masters|Bachelors|Associates|Some college|High school|Less than high school)\s(degree|diploma)'
    value_pattern = r'(\d+\.\d+\%|\$\d+|\d+)'

    # Find all degrees and values dynamically
    degrees = re.findall(degree_pattern, text)
    values = re.findall(value_pattern, text)

    formatted_output = []
    idx = 0

    # Align degrees with their respective values
    for degree in degrees:
        degree_text = " ".join(degree)
        value = values[idx] if idx < len(values) else "N/A"
        formatted_output.append(f"{degree_text}: {value}")
        idx += 1

    # Print formatted lines
    for line in formatted_output:
        print(line)

# Function to extract text from specific pages
def extract_page_text(pdf_path, page_numbers):
    """
    Extract text from specific pages using OCR as a fallback.
    """
    page_data = {}
    with pdfplumber.open(pdf_path) as pdf:
        for page_num in page_numbers:
            try:
                page = pdf.pages[page_num]
                text = page.extract_text()
                if text and len(text.strip()) > 0:
                    page_data[f"Page {page_num+1}"] = clean_text(text)
                else:
                    print(f"No text found on Page {page_num+1}, performing OCR...")
                    page_data[f"Page {page_num+1}"] = ocr_page(pdf_path, page_num)
            except IndexError:
                page_data[f"Page {page_num+1}"] = "Page number out of range."
    return page_data

# Function to extract tabular data
def extract_table_data(pdf_path, page_number):
    """
    Extract and clean table data from a specific page.
    """
    try:
        with pdfplumber.open(pdf_path) as pdf:
            page = pdf.pages[page_number]
            tables = page.extract_tables()
            if tables:
                cleaned_table = [[re.sub(r'\s+', ' ', str(cell).strip()) for cell in row] for row in tables[0]]
                df = pd.DataFrame(cleaned_table[1:], columns=cleaned_table[0])
                print(f"Table extracted successfully from Page {page_number + 1}")
                return df
            else:
                print(f"No tables found on Page {page_number + 1}")
                return pd.DataFrame()
    except Exception as e:
        print(f"Error extracting table from Page {page_number + 1}: {e}")
        return pd.DataFrame()

# PDF File Path
pdf_path = "sample.pdf"

# Extract text and format Page 2
print("----- Page 2: Unemployment Information by Degree -----")
specific_pages = extract_page_text(pdf_path, [1, 5])
page_2_text = specific_pages.get("Page 2", "No data found.")
format_ocr_output(page_2_text)

# Extract and display tabular data from Page 6
print("\n----- Page 6: Tabular Data -----")
page_6_table = extract_table_data(pdf_path, 5)
if not page_6_table.empty:
    print("Extracted Tabular Data:")
    print(page_6_table)
else:
    print("No tabular data found on Page 6.")

!pip install fpdf

from fpdf import FPDF

def save_chunks_to_pdf(chunks, output_file="chunks.pdf"):
    """
    Save text chunks to a PDF file.
    """
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", size=12)

    for i, chunk in enumerate(chunks, 1):
        pdf.multi_cell(0, 10, f"Chunk {i}:\n{chunk}\n\n")

    pdf.output(output_file)
    print(f"PDF saved as {output_file}")

# Assuming 'text' is the extracted text from the PDF
text = "Your extracted or processed text here..."
#Import the necessary module
from langchain.text_splitter import RecursiveCharacterTextSplitter

def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)
    chunks = text_splitter.split_text(text)
    return chunks
chunks = get_text_chunks(text)

if chunks:
    save_chunks_to_pdf(chunks)
    print("Chunks saved to chunks.pdf")

from google.colab import auth
auth.authenticate_user()

!pip install google-cloud-storage google-cloud-aiplatform

import os
os.environ["GOOGLE_CLOUD_PROJECT"] = "your-project-id"  # Replace with your project ID

!pip install faiss-cpu langchain langchain-google-genai

!pip install google-auth # Make sure this is installed

import os
from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings
from langchain.vectorstores import FAISS
import pandas as pd
from google.auth import default  # Import default for credential retrieval

def get_vector_store(text_chunks, pdf_source="default.pdf"):
    try:
        # Specify required scopes
        scopes = [
            "https://www.googleapis.com/auth/cloud-platform",
            "https://www.googleapis.com/auth/generativelanguage"  # Add the generativelanguage scope
        ]

        # Get default credentials with scopes
        credentials, project_id = default(scopes=scopes)

        # Initialize the embeddings model, explicitly passing credentials
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            credentials=credentials
        )

        metadata = [{"source": pdf_source} for _ in text_chunks]
        vector_store = FAISS.from_texts(text_chunks, embedding=embeddings, metadatas=metadata)
        vector_store.save_local("faiss_index")
        print("FAISS index successfully created and saved in 'faiss_index'.")
    except Exception as e:
        print(f"Error creating or saving the FAISS index: {e}")

import shutil
shutil.make_archive("faiss_index", 'zip', "faiss_index")
from google.colab import files
files.download("faiss_index.zip")

!pip install google-auth

import os
from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings
from langchain.vectorstores import FAISS
import pandas as pd
from google.auth import default  # Import default for credential retrieval

def get_vector_store(text_chunks, pdf_source="default.pdf"):
    """
    Create a vector store using FAISS and Google Generative AI embeddings.

    Args:
        text_chunks (list): List of text chunks.
        pdf_source (str): Source PDF file name.

    Saves:
        A FAISS index locally in the directory "faiss_index".
    """
    try:
        # Get default credentials
        credentials, project_id = default()

        # Initialize the embeddings model, explicitly passing credentials
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            credentials=credentials
        )

        metadata = [{"source": pdf_source} for _ in text_chunks]  # Add metadata for tracking
        vector_store = FAISS.from_texts(text_chunks, embedding=embeddings, metadatas=metadata)
        vector_store.save_local("faiss_index")  # Save index to faiss_index directory
        print("FAISS index successfully created and saved in 'faiss_index'.")
    except Exception as e:
        print(f"Error creating or saving the FAISS index: {e}")

!pip install -U langchain-community # This line was added to install the missing package
!pip install langchain-google-genai
!pip install faiss-cpu # or faiss-gpu if you have a CUDA supported GPU

# Import necessary libraries
from langchain_community.vectorstores import FAISS
from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings  # Import from the correct package
from langchain_google_genai import ChatGoogleGenerativeAI  # Import ChatGoogleGenerativeAI from langchain_google_genai
from langchain.prompts import PromptTemplate
import os

# Make sure to set the API key for Google Generative AI
os.environ["GOOGLE_API_KEY"] = "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"  # Replace with your actual API key

# Function to process user query
def user_input(user_question):
    # Initialize embeddings and load FAISS index
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    # Update the path to "faiss_index" to match your directory, and ensure the index file exists
    # If the index was saved with a custom index_name, make sure to provide it here
    new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True, index_name="index")  # Load the FAISS index, allowing deserialization, and specifying index_name
    docs = new_db.similarity_search(user_question)  # Perform similarity search

    # Initialize the conversational chain
    chain = get_conversational_chain()

    # Get the response from the model based on the input query and retrieved documents
    response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)

    # Print the response
    print(f"Query: {user_question}")
    print(f"Response: {response['output_text']}")

    return response['output_text']

# Function to create a conversational chain with Google Generative AI
def get_conversational_chain():
    # Define the conversational model
    model = ChatGoogleGenerativeAI(model="text-bison-001")  # Specify the model name
    prompt_template = "Answer the following question based on the retrieved documents: {question}"

def user_input(user_question):
    embeddings = GoogleGenerativeAIEmbeddings(model = "models/embedding-001")

    new_db = FAISS.load_local("faiss_index", embeddings)
    docs = new_db.similarity_search(user_question)

    chain = get_conversational_chain()


    response = chain(
        {"input_documents":docs, "question": user_question}
        , return_only_outputs=True)

    print(response)
    st.write("Reply: ", response["output_text"])

!pip install streamlit # Make sure streamlit is installed
import streamlit as st # Import streamlit

def main():
    st.set_page_config("Chat PDF")
    st.header("Chat with PDF using Gemini💁")

    user_question = st.text_input("Ask a Question from the PDF Files")

    if user_question:
        user_input(user_question)

    with st.sidebar:
        st.title("Menu:")
        pdf_docs = st.file_uploader("Upload your PDF Files and Click on the Submit & Process Button", accept_multiple_files=True)
        if st.button("Submit & Process"):
            with st.spinner("Processing..."):
                raw_text = get_pdf_text(pdf_docs)
                text_chunks = get_text_chunks(raw_text)
                get_vector_store(text_chunks)
                st.success("Done")



if __name__ == "__main__":
    main()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
#      # Paste your Streamlit code here
# !apt-get install -y tesseract-ocr
# !pip install pdfplumber pytesseract pillow pandas
# !pip install streamlit
# !pip install  google-generativeai
# !pip install  python-dotenv
# !pip install  langchain
# !pip install   PyPDF2
# !pip install  chromadb
# !pip install   faiss-cpu
# !pip install   langchain_google_genai
# !pip install -U langchain-community
# import pdfplumber
# import pytesseract
# from PIL import Image, ImageEnhance, ImageOps
# import pandas as pd
# import re
# 
# # Function to clean and normalize text
# def clean_text(text):
#     """
#     Clean extracted text by removing excessive spaces, newlines, and invalid symbols.
#     """
#     text = re.sub(r'\n+', ' ', text)  # Replace newlines
#     text = re.sub(r'[^\x00-\x7F]+', '', text)  # Remove non-ASCII
#     text = re.sub(r'[^\w\s\.\%\:\$\-]', '', text)  # Keep valid symbols
#     text = re.sub(r'\s+', ' ', text).strip()  # Normalize spaces
#     return text
# 
# # Function to preprocess images for OCR
# def preprocess_image_for_ocr(image):
#     """
#     Preprocess image: grayscale, threshold, contrast enhancement, and resizing.
#     """
#     image = image.convert("L")  # Grayscale
#     image = ImageEnhance.Contrast(image).enhance(2.5)  # Increase contrast
#     image = ImageOps.invert(image)  # Invert for better text visibility
#     image = image.resize((image.width * 2, image.height * 2), Image.Resampling.LANCZOS)  # Resize
#     return image
# 
# # OCR function with fallback to different PSM modes
# def ocr_page(pdf_path, page_number):
#     """
#     Perform OCR with preprocessing and adaptive PSM modes.
#     """
#     try:
#         with pdfplumber.open(pdf_path) as pdf:
#             page = pdf.pages[page_number]
#             image = page.to_image(resolution=300).original
#             image = preprocess_image_for_ocr(image)
# 
#             # First OCR attempt with PSM 6
#             text = pytesseract.image_to_string(image, config="--psm 6")
#             if not text.strip():
#                 # Fallback to PSM 4 for better layout parsing
#                 text = pytesseract.image_to_string(image, config="--psm 4")
#             print(f"OCR performed on Page {page_number + 1}")
#             return clean_text(text)
#     except Exception as e:
#         return f"Error performing OCR on Page {page_number + 1}: {e}"
# 
# # Function to dynamically format and align OCR output
# def format_ocr_output(text):
#     """
#     Dynamically format OCR output into structured lines with labels and values.
#     """
#     # Patterns for degrees, percentages, and monetary values
#     degree_pattern = r'(Doctoral|Professional|Masters|Bachelors|Associates|Some college|High school|Less than high school)\s(degree|diploma)'
#     value_pattern = r'(\d+\.\d+\%|\$\d+|\d+)'
# 
#     # Find all degrees and values dynamically
#     degrees = re.findall(degree_pattern, text)
#     values = re.findall(value_pattern, text)
# 
#     formatted_output = []
#     idx = 0
# 
#     # Align degrees with their respective values
#     for degree in degrees:
#         degree_text = " ".join(degree)
#         value = values[idx] if idx < len(values) else "N/A"
#         formatted_output.append(f"{degree_text}: {value}")
#         idx += 1
# 
#     # Print formatted lines
#     for line in formatted_output:
#         print(line)
# 
# # Function to extract text from specific pages
# def extract_page_text(pdf_path, page_numbers):
#     """
#     Extract text from specific pages using OCR as a fallback.
#     """
#     page_data = {}
#     with pdfplumber.open(pdf_path) as pdf:
#         for page_num in page_numbers:
#             try:
#                 page = pdf.pages[page_num]
#                 text = page.extract_text()
#                 if text and len(text.strip()) > 0:
#                     page_data[f"Page {page_num+1}"] = clean_text(text)
#                 else:
#                     print(f"No text found on Page {page_num+1}, performing OCR...")
#                     page_data[f"Page {page_num+1}"] = ocr_page(pdf_path, page_num)
#             except IndexError:
#                 page_data[f"Page {page_num+1}"] = "Page number out of range."
#     return page_data
# 
# # Function to extract tabular data
# def extract_table_data(pdf_path, page_number):
#     """
#     Extract and clean table data from a specific page.
#     """
#     try:
#         with pdfplumber.open(pdf_path) as pdf:
#             page = pdf.pages[page_number]
#             tables = page.extract_tables()
#             if tables:
#                 cleaned_table = [[re.sub(r'\s+', ' ', str(cell).strip()) for cell in row] for row in tables[0]]
#                 df = pd.DataFrame(cleaned_table[1:], columns=cleaned_table[0])
#                 print(f"Table extracted successfully from Page {page_number + 1}")
#                 return df
#             else:
#                 print(f"No tables found on Page {page_number + 1}")
#                 return pd.DataFrame()
#     except Exception as e:
#         print(f"Error extracting table from Page {page_number + 1}: {e}")
#         return pd.DataFrame()
# 
# # PDF File Path
# pdf_path = "sample.pdf"
# 
# # Extract text and format Page 2
# print("----- Page 2: Unemployment Information by Degree -----")
# specific_pages = extract_page_text(pdf_path, [1, 5])
# page_2_text = specific_pages.get("Page 2", "No data found.")
# format_ocr_output(page_2_text)
# 
# # Extract and display tabular data from Page 6
# print("\n----- Page 6: Tabular Data -----")
# page_6_table = extract_table_data(pdf_path, 5)
# if not page_6_table.empty:
#     print("Extracted Tabular Data:")
#     print(page_6_table)
# else:
#     print("No tabular data found on Page 6.")
# 
# !pip install fpdf
# from fpdf import FPDF
# 
# def save_chunks_to_pdf(chunks, output_file="chunks.pdf"):
#     """
#     Save text chunks to a PDF file.
#     """
#     pdf = FPDF()
#     pdf.set_auto_page_break(auto=True, margin=15)
#     pdf.add_page()
#     pdf.set_font("Arial", size=12)
# 
#     for i, chunk in enumerate(chunks, 1):
#         pdf.multi_cell(0, 10, f"Chunk {i}:\n{chunk}\n\n")
# 
#     pdf.output(output_file)
#     print(f"PDF saved as {output_file}")
# # Assuming 'text' is the extracted text from the PDF
# text = "Your extracted or processed text here..."
# #Import the necessary module
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# 
# def get_text_chunks(text):
#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)
#     chunks = text_splitter.split_text(text)
#     return chunks
# chunks = get_text_chunks(text)
# 
# if chunks:
#     save_chunks_to_pdf(chunks)
#     print("Chunks saved to chunks.pdf")
# 
# !pip install faiss-cpu langchain langchain-google-genai
# 
# from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings  # Import from the correct package
# from langchain.vectorstores import FAISS
# 
# def get_vector_store(text_chunks):
#     """
#     Create a vector store using FAISS and Google Generative AI embeddings.
# 
#     Args:
#         text_chunks (list): List of text chunks.
# 
#     Saves:
#         A FAISS index locally in the directory "faiss_index".
#     """
#     try:
#         # Initialize the embeddings model
#         embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
# 
#         # Create a FAISS vector store
#         vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)
# 
#         # Save the FAISS index locally
#         vector_store.save_local("faiss_index")
#         print("FAISS index successfully created and saved in 'faiss_index'.")
#     except Exception as e:
#         print(f"Error creating or saving the FAISS index: {e}")
# 
# # Example Usage
# if __name__ == "__main__":
#     # Example text chunks
#     text_chunks = ["This is the first chunk.", "Here is the second chunk.", "This is another text chunk."]
# 
#     # Create and save the vector store
#     get_vector_store(text_chunks)
# import shutil
# shutil.make_archive("faiss_index", 'zip', "faiss_index")
# from google.colab import files
# files.download("faiss_index.zip")
# !pip install google-auth
# 
# import os
# from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings
# from langchain.vectorstores import FAISS
# import pandas as pd
# from google.auth import default  # Import default for credential retrieval
# 
# def get_vector_store(text_chunks, pdf_source="default.pdf"):
#     """
#     Create a vector store using FAISS and Google Generative AI embeddings.
# 
#     Args:
#         text_chunks (list): List of text chunks.
#         pdf_source (str): Source PDF file name.
# 
#     Saves:
#         A FAISS index locally in the directory "faiss_index".
#     """
#     try:
#         # Get default credentials
#         credentials, project_id = default()
# 
#         # Initialize the embeddings model, explicitly passing credentials
#         embeddings = GoogleGenerativeAIEmbeddings(
#             model="models/embedding-001",
#             credentials=credentials
#         )
# 
#         metadata = [{"source": pdf_source} for _ in text_chunks]  # Add metadata for tracking
#         vector_store = FAISS.from_texts(text_chunks, embedding=embeddings, metadatas=metadata)
#         vector_store.save_local("faiss_index")  # Save index to faiss_index directory
#         print("FAISS index successfully created and saved in 'faiss_index'.")
#     except Exception as e:
#         print(f"Error creating or saving the FAISS index: {e}")
# 
# !pip install -U langchain-community # This line was added to install the missing package
# !pip install langchain-google-genai
# !pip install faiss-cpu # or faiss-gpu if you have a CUDA supported GPU
# # Import necessary libraries
# from langchain_community.vectorstores import FAISS
# from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings  # Import from the correct package
# from langchain_google_genai import ChatGoogleGenerativeAI  # Import ChatGoogleGenerativeAI from langchain_google_genai
# from langchain.prompts import PromptTemplate
# import os
# 
# # Make sure to set the API key for Google Generative AI
# os.environ["GOOGLE_API_KEY"] = "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"  # Replace with your actual API key
# 
# # Function to process user query
# def user_input(user_question):
#     # Initialize embeddings and load FAISS index
#     embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
#     # Update the path to "faiss_index" to match your directory, and ensure the index file exists
#     # If the index was saved with a custom index_name, make sure to provide it here
#     new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True, index_name="index")  # Load the FAISS index, allowing deserialization, and specifying index_name
#     docs = new_db.similarity_search(user_question)  # Perform similarity search
# 
#     # Initialize the conversational chain
#     chain = get_conversational_chain()
# 
#     # Get the response from the model based on the input query and retrieved documents
#     response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
# 
#     # Print the response
#     print(f"Query: {user_question}")
#     print(f"Response: {response['output_text']}")
# 
#     return response['output_text']
# 
# # Function to create a conversational chain with Google Generative AI
# def get_conversational_chain():
#     # Define the conversational model
#     model = ChatGoogleGenerativeAI(model="text-bison-001")  # Specify the model name
#     prompt_template = "Answer the following question based on the retrieved documents: {question}"
# 
# def user_input(user_question):
#     embeddings = GoogleGenerativeAIEmbeddings(model = "models/embedding-001")
# 
#     new_db = FAISS.load_local("faiss_index", embeddings)
#     docs = new_db.similarity_search(user_question)
# 
#     chain = get_conversational_chain()
# 
# 
#     response = chain(
#         {"input_documents":docs, "question": user_question}
#         , return_only_outputs=True)
# 
#     print(response)
#     st.write("Reply: ", response["output_text"])
# !pip install streamlit # Make sure streamlit is installed
# import streamlit as st # Import streamlit
# 
# def main():
#     st.set_page_config("Chat PDF")
#     st.header("Chat with PDF using Gemini💁")
# 
#     user_question = st.text_input("Ask a Question from the PDF Files")
# 
#     if user_question:
#         user_input(user_question)
# 
#     with st.sidebar:
#         st.title("Menu:")
#         pdf_docs = st.file_uploader("Upload your PDF Files and Click on the Submit & Process Button", accept_multiple_files=True)
#         if st.button("Submit & Process"):
#             with st.spinner("Processing..."):
#                 raw_text = get_pdf_text(pdf_docs)
#                 text_chunks = get_text_chunks(raw_text)
#                 get_vector_store(text_chunks)
#                 st.success("Done")
# 
# 
# 
# if __name__ == "__main__":
#     main()
#

!ls /content/

!streamlit run app.py & npx localtunnel --port 8501